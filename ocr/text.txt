I'd like to begin this paper -- as I often seem to do -- by revising my title. I've used the word "vestigial" to invoke a sense in which functionally formal elements of a design persist beyond their specific practicalities and instead become aesthetic remainders. I'm not sure that the biological, evolutionary metaphor is entirely appropriate. Nor am I convinced that skeuomorphism fully captures the phenoma of typeface functionally []

I'm interested in talking today about a particular typeface, OCR-A, and I'd like to trace the significance of some of its applications back to the context in which it originated. The occasion of this panel on a media archaoelogical approach to "the invisible and unwanted", provides two convenient frames from which to hang a series of provocative questions: 

First, *invisibility* is an ironically appropriate for discussing typography, since it operates within the particular sub-visibility of graphic design whereby it is often said to work best when it is noticed least. [quote?]

Second, media archaeology, as I understand it, is a way of doing media theory with a historical perspective toward the conditions and possibilities that make culture artifacts possible. For OCR-A, this question of conditions, possibilities and necessities steps in as an answer to the question that began my interest in OCR-A. Namely, why does OCR-A appear so frequently in design instances related to videogames, particularly when the apparent intent of the design is to create an association with older games? In fact, OCR-A was intended to make alphanumeric characters printed in ink more reliably readable by data processing machines. It was never intended for screen display and is rarely, if at all, used in videogame packaging or arcade cabinet design through at least the 1980s. So as it turns out, this association is anachronistic, but still the history of OCR-A's development may still yield some clues that point toward something more nuanced than that it simply "looks technical." 

The basic process and necessity for Optical Character Recognition technology is familiar to anyone who has worked in archives or who has searched for something in Google Books. A digital scan of a page image is examined by character recognition software that identifies specific alphabetic graphemes and converts them into some digital format such as ASCII. It is the workflow by which, for example, Google Books is converting "all of the worlds knowledge" [] into an indexical format. 

OCR technology generally works well enough that from a readerly point of view, we tend only to notice it when it fails, at which point its artifacts become aesthetic. For example, the reCaPTCHA service combines OCR recognition with a human input element to create a digital shibboleth for users of websites. This is an authentication barrier challenging the user to prove that she is not a machine while, at the same time, recruiting her human subjectivity to account for an OCR machine's failure to recognize some text. What the user sees is two words: one, already known to the software, has been artificially distorted to baffle further machine translation, the other is organically distorted by the vaguaries of the printing or scanning process. The juxtaposition of these two barely readable words occasionally leads to amusing or evocative, including a series of comics attempting to illustrate the text and the more fully emplotted saga of inglip. But these are interesting for how they exploit the oddness that lies at the threshold between machine readability and human subjectivity, positioning the latter as the Other of the former.

Another, less narrowly defined application of OCR's failures toward aesthetics is the aptly named Tumblr blog, "The Art of Google Books," which simply archives the oddness that can be found among Google's [quadrillion or so] scanned pages. What's interesting, again, is how human subjectivity is only evident when it creates noise, error, or other mitigations against the imaginary one-to-one conversion of text to data.

Nowadays, the human computer relationship is largely a question of interfaces built on metaphors, but in the earliest implementations of mainframe computers, where the primary business tasks related to computing involved processing or storing large sets of data, efficient and reliable data entry was an important early problem to solve. A 1970 handbook on applications of OCR characterizes this as [a human computer problem], where, of the two parties involved, the issue is with the human. OCR-A was an attempt to solve that problem through standardization.

The earliest demonstrations of optical character recognition date back to 1914 when [what's his name] did [whatever that process was]. OCR also figures into Vannevar Bush's oft-cited Memex device as well as [that other one he worked on]. 

But by the early 1960s, OCR advocates and inventors like Jacob Rabinow, who had consulted with Bush on the Memex, were calling for an industry standard to support the development of the technology as well as the emerging secondary industry in providing OCR solutions for businesses. Computers were being used to process, calculate, and track more and more information, and standardized OCR leveraged the durability of ink and paper to replace slower, more fragile systems like [whatever the name is] punch cards.

In the United States, the solution to this problem, the typeface we now know as OCR-A, took shape in the mid-1960s, with implementations as early as 1966. The full type definition was not publicly available until the 1968 publication of x.3. [whatever] document, by the USA Standards Institute (which later became the more familiar ANSI), in accordance with ISO standard [whatever]. This document defines details of the font in minute detail, down to relative stroke widths and ink smudge tolerance, because its provenance is entirely technical. Throughout the document, though the human reader is implied, it is clear that the primary audience for text printed in this font is the OCR reading device. Thus, the shapes of each character become constrained and distorted by the affordances of that reading machines resolution and tolerance for error. Great care is taken, for example, to distingish between otherwise similar characters such as I, l and 1 or O, 0 and D. 

The result is a font that mixes serif with sans-serif characters, shifts axes and internal symmetry haphardzardly, and is easily recognizable through its acute angularity. In these ways, OCR-A is an ugly font, but that ugliness makes it considerable less "invisible" than, say, Helvetica, in a way that is directly tied to its technical function. Note how this inverts the situation recognized in The Art of Google Books where the human element creates the technical remainder. Here it is precisely the characteristics of OCR-A that are NOT intended for humans that lead to its aesthetic function.

With the question here of readership and readability coming to imply both human and machine subjectivities, it is worth noting, with some irony, that the first major business use of OCR-A was in 1966 at Reader's Digest, which used OCR-A in reading, processing and printing and reading address labels. [can I find a image of that?] OCR-A thus supported reader's digestion of literature by enabling the digestion of readers by computers.

Seeking a middle ground, type designer Adrian Frutiger received a commission by ECMA to create a viable alternative to OCR-A. Writing in a typography journal in 1967, Frutiger declared that OCR-A was "barely readable" and "offensive to human taste." His solution in the OCR-B font ([iso standard whatever]) is much gentler and internally consistent, mainly owing to its use of curved lines. Like OCR-A, OCR-B is still attuned the felicities of machine resolution and the affordances of smudging and other vaguaries, but its design documentation and advocacy make the strong case, often in somewhat strident tones, that human readership is a much higher priority than is the case for OCR-A.

Perhaps it is this stridency on behalf of OCR-B that led Jacob Rabinow, writing for the industry journal _Datamation_ in 1969, to speak out in defence of the A standard. First noting that, so far as he knows, no one had yet been injured by OCR-A, Rabinow proceeds to dismantle several of Frutigers claim. Interestingly for a trade journal, Rabinow brackets a more technical description of OCR-B's shortcomings and instead calls into question the supposed aesthetic superiority of OCR-B.

[longer quote]

[graphlex camera image]

[lartigue image]

[bus image]

As technical functions become vestiges for aesthetic paradigms for industrial design, what we see here in 1969 as a defense of OCR-A is an articulation of the specific design patterns William Gibson would later explore in "The Gernsback Continuum" as [did he give it this name?] the Raygun Gothic. This futurism for a future that didn't or hasn't yet happened.

Already by the late 1960s, OCR-A had joined other systems like barcodes and Magnetic Ink Character Recognition (MICR) as part of the informational layer on day to reality, particular in retail environments. But unlike the ubiquitous barcodes and the MICR font e-13b that still appears on paper checks, OCR-A as a specific implementation drifted much more readily out of the functional domain and into aesthetics, as scanning hardware improved image resolution and software has improved beyond the necessity of such a stylized alphabet. Though there are still applicatons for OCR-A, one is much more likely to encounter it in graphic design, where -- owing to its angularity -- OCR-A is typically classified as a font for titles and display, as opposed to body text.

Here are just a few examples where OCR-A appears in book titles. Any apparent thematic continuity among these titles could owe something to the coincidence of being on my bookshelves -- it's difficult, after all, to query a database of books for which typefaces are used in cover art -- or, more likely, it could be that there is a recurring association created by these paratexts.

In a more striking illustration of thematic continuity between text and paratext vis a vis typeface occurs in a series of book covers by [penguin? whoever?] for William Gibson's novels and short story collections. Gibson's fiction expresses a range of ideas dealing with personal memory, the durability of storage media, artifical subectivies, and the obsolescence of futuristic product industrial design, all of which could also describe the specific cultural, economic, and commercial situations which created the need that OCR-A met in the 1960s.  

The 1999 film, The Matrix, OCR-A plays a role in a significant plot point. It's presence could have something to do with the obvious influence of Gibson's cyberpunk on the look of the film, or it could be something more specific. In the first act, Agent Smith sits across a table to interrogate Neo. This is the first scene when viewers become convinced that something is well and truly not right with the world, and as a possible hint toward what that might be, the file Agent Smith reads from is printed entirely in OCR-A. That is, a font created to be read by machine eyes is here being perused by a machine masquerading as a human inside of a simulation.

Each of these applicatons of OCR-A, from the functional to the aesthetic, accumulates associations and resonances that tie together the cultural, material, and economic conditions that brought it into being as well as those that justify its inclusion as a thematic design element. The relationship between videogames and OCR-A reflects this as well. 

One final bit of evidence ties this up nicey in the signage produced for the Art of Videogames Exhibit recently at the Smithsonian American Art Museum. Here, in a gallery full of pristine game consoles displayed alongside video of their respective library of games, each piece of signage or information text is printed in OCR-A. OCR-A actually predates any console on display at the Smithsonian by at least 10 years, placing it squarely in the era of those consoles' forerunners like Spacewar and the Brown Box. Here, the associative logic of the font's aesthetic remainder comes full circle as it sits alongside game console hardware that has been practically fetishized in a way that gives it cultural life beyond its obsolescence. Another example of how the vestiges of obsolescence shift into the aesthetic domain as they become the means by which we tell stories about the past.





