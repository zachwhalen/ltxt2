I'd like to begin this paper -- as I often seem to -- by revising my title, where I've used the word "vestigial" for functionally formal elements of a design that persist beyond their specific practicalities but survive aesthetic remainders. On reflection, I'm not sure that the biological, evolutionary metaphor is entirely appropriate. Nor am I convinced that skeuomorphism fully captures the phenoma of typeface functionally, since I understand that term to describe a backwards-looking process where obsolete function becomes a metaphor for new function. Instead, I think holomorphosis might better capture the phenomenon I wish to explore today, where an artifact of one outmoded process becomes emblematic of other, contemporaneous processes. 

In any case, I'm interested in talking today about a particular typeface or font, OCR-A, and I'd like to trace the significance of some of its design applications back to the context in which it originated. The occasion of this panel on a media archaoelogical approach to "the invisible and unwanted", provides two convenient frames from which to explore this significance.

First, invisibility is an ironically appropriate concept for discussing typography, since type operates within the particular sub-visibility of graphic design whereby it is often said to work best when it is noticed least. As Beatrice Warde states in her exquisitely Modernist essay, "The Crystal Goblet", "The book typographer has the job of erecting a window between the reader inside the room and that landscape which is the author's words." Even if OCR-A is a relatively "opaque" font, its uses outside of optical character recognition eclipse the specific circumstances constraining each of its letters.

A second useful frame for this panel, media archaeology is, as I understand it a way of doing media theory with a historical perspective toward the conditions and possibilities that make culture possible. For OCR-A, its conditions, possibilities and necessities are one answer to the question that began my interest in OCR-A. That is, why is it that OCR-A appears so frequently in paratextual design related to videogames, particularly if the apparent intent of the design is to create an association with older games? In fact, since OCR-A was intended to make alphanumeric characters printed in ink more reliably readable by data processing machines, it was never intended for screen display and is rarely, if at all, used in videogame packaging or arcade cabinet design until the 1990s. In other words, its retrogame association is anachronistic. Even so, the history of OCR-A's development and the way its design emblematizes that history reveals a patterning toward obsolescence characteristic of how we tell stories about the futures of technology's past.

The basic processes and applications for Optical Character Recognition technology are familiar to anyone who has worked in digitizing documents or who has searched for something in Google Books. Basically, a digital scan of a page image is examined by software that identifies specific alphabetic graphemes and converts them into some digital format such as ASCII. This is the workflow by which, for example, Google Books is converting "all of the worlds knowledge" into an indexical format, ready for searching, collecting and n-gramming.

This all generally works well enough that, from a readerly point of view, we tend only to notice it when it fails. This is the point at which its byproducts have the potential to become aesthetic artifacts. For example, reCaPTCHA is a service that combines OCR recognition with a human input element. It creates an authentication barrier asking the user to prove that she is not a machine while, at the same time, recruiting her human subjectivity read some word that the OCR software could not make out. What the user sees is two words: one, already known to the software, has been artificially distorted to baffle further machine translation; the other is just organically distorted by the vaguaries of the printing or scanning process. The juxtaposition of these two barely readable words can be provocative or amusing, enough to provide punchlines for webcomics and an entire "saga of inglip" that in treats recaptcha word pairs as commands issued from a mysterious, possibly lovecraftian horror. These comics and other manipulations like them exploit the oddness that lies at the threshold between machine readability and human subjectivity, positioning the latter as the Other of the former.

Extending a similarly liminal subjectivity, a tumblr blog by Krissy Wilson showcases "The Art of Google Books," appropriating the errata of Google's OCR with a new aesthetic sensibility, often showing the traces of the unnamed owners, donors, readers, or archivists of these books who preside over the twilight of their material specificity. Like the phenomenon of captcha art, this "adversaria" of the miscellany of Google's 20 million or so books is interesting because it only becomes evident when the otherwise smooth process of text encoding becomes too noisy. Error, or some other mitigations against the imaginary one-to-one conversion of text to data intervenes, and that error is almost always human.

Nowadays, the human computer relationship is largely a question of interfaces built on metaphors, but in the earliest implementations of mainframe computers, where the primary business tasks relegated to computing involved the processing or storing large sets of data, efficient and reliable data entry was an important early problem to solve. A 1970 handbook on OCR acknowledges that, "Each day it becomes more evident that our large and complex computers do no operate in a void but in a social environment where they communicate with human beings as well as with other data processing equipment." This book elaborates that within the data-processing domain, there is a human-computer problem where, of the two parties involved, culpability lies with the human who is slow and prone to error. OCR-A was the product of an attempt to solve that problem through standardization.

The earliest demonstrations of optical typographic character recognition date back to the late 19th century, and a 1914 patent for a "Photoprinting Apparatus" is the first practical demonstration of something like modern OCR in an industrial context. Large-scale data processing began to develop in scientific and military computing with the development of mainframe computing through the 1940s. But by the early 1960s, OCR advocates and inventors like Jacob Rabinow, who had consulted with Bush on the Memex, were calling for an industry standard to support the development of the technology as well as the emerging secondary industry in providing OCR solutions. Computers were being used to process, calculate, and track more and more information, and standardized OCR leveraged the durability of ink and paper to replace slower, more fragile systems like Hollerith punch cards.

In the United States, one solution to this problem, the typeface we now know as OCR-A, took shape in the mid-1960s, with implementations as early as 1966. The full type definition released in USASI document X3.17-1966. In this document, a committee of the United States of America Standards Insitute (later, the American National Standards Institute [ANSI]), defines details of the font in minute detail, down to relative stroke widths and ink smudge tolerance. Because USASI's province is technical, throughout the document, although the human reader is implied, it is clear that the primary reader intended for text printed in this font is the OCR reading device itself. Thus, the shapes of each character become constrained and distorted by the affordances of the reading machine's resolution and tolerance for error. Great care is taken, for example, to distingish between otherwise similar characters such as apital I, lowercase l and the numeral 1 or between O, 0 and D. 

The result is a font that mixes serif with sans-serif characters, shifts its axes and internal symmetry haphardzardly, and is easily recognizable through its acute angularity. In these ways, OCR-A is an ugly font, but of course that ugliness -- a human consideration -- makes it less "invisible" than, say, Helvetica, in a way that is directly tied to its technical function. Note how this inverts the situation recognized in The Art of Google Books where the human element creates the technical remainder. Here it is precisely the characteristics of OCR-A that are NOT intended for humans that lead to its aesthetic function.

With the question here of readership and readability coming to imply both human and machine subjectivities, it is worth noting, with some irony, that the first major business use of OCR-A was in 1966 at Reader's Digest, which used OCR-A in reading, processing and printing and reading address labels. [can I find a image of that?] OCR-A thus supported reader's digestion of literature by enabling the digestion of readers by computers.

Seeking a middle ground, type designer Adrian Frutiger received a commission by ECMA to create a viable alternative to OCR-A. Writing in a typography journal in 1967, Frutiger declared that OCR-A was "barely readable" and "offensive to human taste." His solution in the OCR-B font, while still a monospace font with technical constrain, is much gentler and internally consistent, mainly owing to its use of curved lines. Like OCR-A, OCR-B is still attuned the felicities of machine resolution and the affordances of smudging and other vaguaries, but its design documentation and advocacy make the strong case, often in somewhat strident tones, that human readership is a much higher priority than is the case for OCR-A.

Perhaps it is Frutiger's stridency on behalf of OCR-B that led Jacob Rabinow, writing for the industry journal _Datamation_ in 1969, to speak out in defence of the A standard. First noting that, so far as he knows, no one had yet been injured by OCR-A, nor had anyone required psychiatric consultation. After using it for some time at his office, he notes that "No one seems to notice it."

Rabinow continues by bracketing off a more technical description of OCR-B's shortcomings and instead calling into question the supposed aesthetic superiority of OCR-B.

  The esthetics of characters vary with time and place in history. The serifs which we know today are based on something that happened in the Roman times due, some believe, to the problems of chiseling into stone. 
	
Turning to a broader consideration of how shapes enter folklore, describing how turn-of-the century photographs of cars in motion, due to the gradual exposure of the film in the Graflex camera's mechanism, printed images of fast cars seemed to lean forward. 

	This distortion has become so ingrained in our conscience that all cartoonists draw cars leaning forward when they want to indicate speed and the windows in our buses have their vertical lines tilting forward, and for the same reason. It is interesting to think what would have happened if the Graflex camera shutters moved up instead of down.
	
The implication of this diversion, Rabinow makes clear a couple of paragraphs later, 
	
	Suppose the aerodynamic drag were lower for blunt, square objects -- what would have happened to the streamlining of our toasters and washers?

As technical functions become vestiges for aesthetic paradigms in industrial design, what we see here in 1969 as a defense of OCR-A's viability becomes an articulation of the specific design patterns William Gibson would later explore in "The Gernsback Continuum", giving it the name "Raygun Gothic." 

Already by the late 1960s, OCR-A had joined other systems like barcodes and Magnetic Ink Character Recognition (MICR) as part of the informational layer on day to reality, particular in retail environments. But unlike the ubiquitous barcodes and the MICR font e-13b that still appears on paper checks, OCR-A as a specific implementation drifted much more readily out of the functional domain and into aesthetics, as scanning hardware improved image resolution and software has improved beyond the necessity of such a stylized alphabet. Though there are still applicatons for OCR-A, one is much more likely to encounter it in graphic design, where -- owing to its angularity -- OCR-A is typically classified as a font for titles and display, as opposed to body text.

Here are just a few examples where OCR-A appears in book titles. Any apparent thematic continuity among these titles could owe something to the coincidence of being on my bookshelves -- it's difficult, after all, to query a database of books for which typefaces are used in cover art -- or, more likely, it could be that there is a recurring association created by these paratexts.

In a more striking illustration of thematic continuity between text and paratext vis a vis typeface occurs in several of William Gibson's novels and short story collections, including Burning Chrome, which anthologizes his Gernsback Continuum just after the cyberpunk Johnny Mnemonic. These uses of OCR-A and OCR-B are certainly appropriate because Gibson's fiction expresses a range of ideas dealing with personal memory, the durability of storage media, artifical subectivies, and the obsolescence of futuristic product industrial design, all of which could also address the specific cultural, economic, and commercial situations which created the need that OCR-A met in the 1960s.  

Continuing the cyberpunk theme 1999 film, The Matrix, OCR-A actually plays a role in a significant plot point. It's presence could have something to do with the obvious influence of Gibson's fiction on the general look of the film, or it could be something more specific when, in the first act, Agent Smith sits across a table to interrogate Neo. This is the first scene when viewers might become convinced that something is well and truly not right with the world, and as a foreshadow of what that might actually be, the file Agent Smith reads from is printed entirely in OCR-A. That is, a font created to be read by machine eyes is here being perused by a machine masquerading as a human inside of a simulation.

Each of these applicatons of OCR-A, from the functional to the aesthetic, accumulates associations and resonances that tie together the cultural, material, and economic conditions that brought it into being as well as those that justify its inclusion as a thematic design element. The relationship between videogames and OCR-A reflects this as well. 

One final bit of evidence ties this up nicely in the signage produced for the Art of Videogames Exhibit recently at the Smithsonian American Art Museum. Here, in a gallery full of pristine game consoles displayed alongside video of their respective library of games, each piece of signage or information text is printed in OCR-A. OCR-A actually predates any console on display at the Smithsonian by at least 10 years, placing it squarely in the era of those consoles' forerunners like Spacewar and the Brown Box. Here, the associative logic of the font's aesthetic remainder comes full circle as it sits alongside game console hardware that has been practically fetishized in a way that gives it cultural life beyond its obsolescence. Another example of how the vestiges of obsolescence shift into the aesthetic domain as they become the means by which we tell stories about the past.





